{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42449582",
   "metadata": {},
   "source": [
    "# 斷詞\n",
    "以下使用中研院ckip斷詞套件將貼文與留言內容斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97977bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow ckiptagger gdown pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1de7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c51793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethancy/fb_crawling/venv/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:909: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "/Users/ethancy/fb_crawling/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# 載入ckip斷詞模型\n",
    "ws = WS(\"./src/ckip_data/\")\n",
    "pos = POS(\"./src/ckip_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82118485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "斷詞前要拿掉的字詞 共130 個 e.g. ['\\n', '新聞雲', '快下載新聞雲App掌握政治大小事', '熱門話題一手掌握', '下載']\n",
      "我預先定義的字詞 共55個 e.g. ['振興券', '消費券', '三倍券', '三倍', '經濟部']\n",
      "正向用字: 共2810個 e.g. ['一帆風順', '一帆風順的', '一流', '一致', '一致的']\n",
      "負向用字: 共8274個 e.g. ['一下子爆發', '一下子爆發的一連串', '一巴掌', '一再', '一再叮囑']\n"
     ]
    }
   ],
   "source": [
    "# 載入停用字與我定義的字典\n",
    "from data.my_configs import remove_patterns, predefined_words, positive_words, negative_words, selected_pos_types\n",
    "# 停用字這些是要在斷詞前先拿掉的\n",
    "print(f'斷詞前要拿掉的字詞 共{len(remove_patterns)} 個 e.g. {remove_patterns[:5]}')\n",
    "# 這是提供給斷詞套件參考的詞典\n",
    "print(f'我預先定義的字詞 共{len(predefined_words)}個 e.g. {predefined_words[:5]}')\n",
    "# 這是預先下載好了正向與負向情緒用字\n",
    "print(f'正向用字: 共{len(positive_words)}個 e.g. {positive_words[:5]}')\n",
    "print(f'負向用字: 共{len(negative_words)}個 e.g. {negative_words[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa02e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依照詞典的內容，建構給ckip斷詞套件的辭典\n",
    "word_to_weight = {word : 1 for word in predefined_words+positive_words+negative_words}\n",
    "dictionary = construct_dictionary(word_to_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eef50b",
   "metadata": {},
   "source": [
    "# 貼文斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1102ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-70e690e7fdd8>:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  posts['content_and_link_title'] = posts['content_and_link_title'].str.replace(remove_pattern, \"\")\n",
      "<ipython-input-6-70e690e7fdd8>:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  posts['content_and_link_title'] = posts['content_and_link_title'].str.replace(remove_pattern, \"\")\n"
     ]
    }
   ],
   "source": [
    "#讀入貼文\n",
    "posts = pd.read_csv(\"./data/refined/posts_v1.csv\")\n",
    "\n",
    "#把小編發文內容與連結中的新聞標題組在一起\n",
    "posts['content_and_link_title'] = posts['post_content'].fillna('') + posts['link_title'].fillna('')\n",
    "\n",
    "#把停用字詞拿掉\n",
    "for remove_pattern in remove_patterns:\n",
    "    posts['content_and_link_title'] = posts['content_and_link_title'].str.replace(remove_pattern, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b79d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 10.4 s, total: 1min 17s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 斷詞\n",
    "## ckip cut\n",
    "post_seg_list = ws(\n",
    "    posts['content_and_link_title'],\n",
    "    sentence_segmentation = True, # To consider delimiters\n",
    "    coerce_dictionary = dictionary, # words in this dictionary are forced\n",
    ")\n",
    "\n",
    "post_seg_list = [[ seg.replace(\"\\n\",\"\") for seg in seg_list] for seg_list in post_seg_list]\n",
    "post_pos_list = pos(post_seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41fc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把貼文的斷詞結果和詞性存成檔案\n",
    "with open(\"./data/refined/post_seg.txt\",'w') as f:\n",
    "    for line in post_seg_list:\n",
    "        f.write(\" \".join(line))\n",
    "        f.write(\"\\n\")\n",
    "with open(\"./data/refined/post_pos.txt\",'w') as f:\n",
    "    for line in post_pos_list:\n",
    "        f.write(\" \".join(line))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98095509",
   "metadata": {},
   "source": [
    "# 留言斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957dae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "<timed exec>:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 794 ms, total: 26.2 s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comments = pd.read_csv(\"./data/refined/comments.csv\")\n",
    "# 去除空的留言，空的留言可能是只有留貼圖或其他無法辨識的內容\n",
    "comments = comments[comments['comment'].notnull()].reset_index(drop=True) \n",
    "\n",
    "# 去除不要的字詞\n",
    "for remove_pattern in remove_patterns:\n",
    "    comments['comment'] = comments['comment'].str.replace(remove_pattern, \"\")\n",
    "    \n",
    "# 將每則貼文底下，同一個人的所有留言歸到同一則內\n",
    "comments_by_author = comments.groupby(['post_url','author'])['comment'].apply(lambda x:\"\".join(x)).reset_index()\n",
    "\n",
    "# 去除留言中tag人名，有些人的留言純粹只是想請朋友來看，我們暫時先把這類型排除在分析之外\n",
    "name_pattern_ser = [pat.replace(\" \",\"\") for pat in comments_by_author['author'].unique()]\n",
    "name_pattern = \"|\".join(name_pattern_ser)\n",
    "\n",
    "pool = mp.Pool(processes=max(mp.cpu_count() - 1 ,1) )\n",
    "pool_res = pool.starmap( re.sub,[[name_pattern, \"\", row] for row in comments_by_author['comment']])\n",
    "pool.close()\n",
    "pool.join()\n",
    "comments_by_author['comment_no_ppl_tag'] = [i for i in pool_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497d542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_url</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_no_ppl_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.facebook.com/ETtoday/posts/3150078...</td>\n",
       "      <td>Angel Lee</td>\n",
       "      <td>現在不促進觀光時候全民自主管理最安全先把那個錢省下來防疫工作不知道何時才會停止還有隔離醫療先...</td>\n",
       "      <td>現在不促進觀光時候全民自主管理最安全先把那個錢省下來防疫工作不知道何時才會停止還有隔離醫療先...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.facebook.com/ETtoday/posts/3150078...</td>\n",
       "      <td>Barry Shin</td>\n",
       "      <td>對於疫情處理好壞看看周圍亞洲各國你應該慶幸在台灣這篇留言串不知道什麼吊出很多群情激憤網民看起...</td>\n",
       "      <td>對於疫情處理好壞看看周圍亞洲各國你應該慶幸在台灣這篇留言串不知道什麼吊出很多群情激憤網民看起...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com/ETtoday/posts/3150078...</td>\n",
       "      <td>Bau Bear</td>\n",
       "      <td>好事把消費留在國內</td>\n",
       "      <td>好事把消費留在國內</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.facebook.com/ETtoday/posts/3150078...</td>\n",
       "      <td>Benny Hsieh</td>\n",
       "      <td>賴宥蓁不然呢哪個建設和政策不花人民錢很正常</td>\n",
       "      <td>不然呢哪個建設和政策不花人民錢很正常</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.facebook.com/ETtoday/posts/3150078...</td>\n",
       "      <td>Bling Bling Lin</td>\n",
       "      <td>花菲菲撐過215國內觀光就不怕</td>\n",
       "      <td>花菲菲撐過215國內觀光就不怕</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            post_url           author  \\\n",
       "0  https://www.facebook.com/ETtoday/posts/3150078...        Angel Lee   \n",
       "1  https://www.facebook.com/ETtoday/posts/3150078...       Barry Shin   \n",
       "2  https://www.facebook.com/ETtoday/posts/3150078...         Bau Bear   \n",
       "3  https://www.facebook.com/ETtoday/posts/3150078...      Benny Hsieh   \n",
       "4  https://www.facebook.com/ETtoday/posts/3150078...  Bling Bling Lin   \n",
       "\n",
       "                                             comment  \\\n",
       "0  現在不促進觀光時候全民自主管理最安全先把那個錢省下來防疫工作不知道何時才會停止還有隔離醫療先...   \n",
       "1  對於疫情處理好壞看看周圍亞洲各國你應該慶幸在台灣這篇留言串不知道什麼吊出很多群情激憤網民看起...   \n",
       "2                                          好事把消費留在國內   \n",
       "3                              賴宥蓁不然呢哪個建設和政策不花人民錢很正常   \n",
       "4                                    花菲菲撐過215國內觀光就不怕   \n",
       "\n",
       "                                  comment_no_ppl_tag  \n",
       "0  現在不促進觀光時候全民自主管理最安全先把那個錢省下來防疫工作不知道何時才會停止還有隔離醫療先...  \n",
       "1  對於疫情處理好壞看看周圍亞洲各國你應該慶幸在台灣這篇留言串不知道什麼吊出很多群情激憤網民看起...  \n",
       "2                                          好事把消費留在國內  \n",
       "3                                 不然呢哪個建設和政策不花人民錢很正常  \n",
       "4                                    花菲菲撐過215國內觀光就不怕  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_by_author.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd63321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 46min 14s, sys: 15min 24s, total: 2h 1min 38s\n",
      "Wall time: 22min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ckip cut\n",
    "comment_seg_list = ws(\n",
    "    comments_by_author['comment_no_ppl_tag'],\n",
    "    sentence_segmentation = True, # To consider delimiters\n",
    "    coerce_dictionary = dictionary, # words in this dictionary are forced\n",
    ")\n",
    "comment_seg_list = [[ seg.replace(\"\\n\",\"\") for seg in seg_list] for seg_list in comment_seg_list]\n",
    "comment_pos_list = pos(comment_seg_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb4d7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把留言的斷詞結果和詞性存成檔案\n",
    "with open(\"./data/refined/comment_seg.txt\",'w') as f:\n",
    "    for line in comment_seg_list:\n",
    "        f.write(\" \".join(line))\n",
    "        f.write(\"\\n\")\n",
    "with open(\"./data/refined/comment_pos.txt\",'w') as f:\n",
    "    for line in comment_pos_list:\n",
    "        f.write(\" \".join(line))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c29b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "選擇詞性['A', 'Na', 'Nb', 'Nc', 'Ncd', 'Nd', 'Nv', 'VA', 'VAC', 'VB', 'VC', 'VCL', 'VD', 'VE', 'VF', 'VG', 'VH', 'VHC', 'VI', 'VJ', 'VK', 'V_2', 'FW']\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "exclude_pos = True\n",
    "if exclude_pos:\n",
    "    print(f'選擇詞性{selected_pos_types}')\n",
    "    posts['word_list'] = [[seg for seg, pos in zip(seg_list, pos_list) if pos in selected_pos_types] for seg_list, pos_list in zip(post_seg_list, post_pos_list)]\n",
    "    comments_by_author['word_list'] = [[seg for seg, pos in zip(seg_list, pos_list) if pos in selected_pos_types] for seg_list, pos_list in zip(comment_seg_list, comment_pos_list)]\n",
    "else:\n",
    "    posts['word_list'] = post_seg_list\n",
    "    comments_by_author['word_list'] = comment_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6241ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 495 ms, total: 2min\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "posts['sentiment_pos'] = posts['word_list'].apply(lambda x:sum([i in x for i in positive_words]))\n",
    "posts['sentiment_neg'] = posts['word_list'].apply(lambda x:sum([i in x for i in negative_words]))\n",
    "posts['sentiment_score'] = (posts['sentiment_pos']/(posts['sentiment_pos']+posts['sentiment_neg']))#.fillna(0.5).mean()\n",
    "\n",
    "posts[\"sentiment_score_filled\"] = posts['sentiment_score'] \n",
    "posts[\"sentiment_score_filled\"] = posts.groupby(\"fanpage\")['sentiment_score'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "comments_by_author['sentiment_pos'] = comments_by_author['comment_no_ppl_tag'].apply(lambda x:sum([i in x for i in positive_words]))\n",
    "comments_by_author['sentiment_neg'] = comments_by_author['comment_no_ppl_tag'].apply(lambda x:sum([i in x for i in negative_words]))\n",
    "comments_by_author['sentiment_score'] = (comments_by_author['sentiment_pos']/(comments_by_author['sentiment_pos']+comments_by_author['sentiment_neg']))#.fillna(0.5).mean()\n",
    "comments_by_author[\"sentiment_score_filled\"] = comments_by_author['sentiment_score'].fillna(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a978c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv(\"./data/refined/post_with_seg.csv\",index=None)\n",
    "comments_by_author.to_csv(\"./data/refined/comments_by_author_with_seg.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1089817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c61a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ba9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1033cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
